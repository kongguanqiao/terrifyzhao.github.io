---
layout: post
title: 'PCA主成分分析'
subtitle: 'PCA推导全过程'
date: 2018-02-28
categories: 机器学习
cover: 'https://raw.githubusercontent.com/terrifyzhao/terrifyzhao.github.io/master/assets/img/2018-02-28-%E5%86%B3%E7%AD%96%E6%A0%91/cover.jpeg'
tags: 机器学习
---

## 前言

之前看过的大部分PCA博文都是只介绍了PCA的计算流程，对其中的推导过程与原理并没有详细介绍，这篇文章的目的是介绍PCA的基本数学原理，手推PCA每一个步骤，帮助读者了解PCA的工作机制是什么。对于文中的某些数学公式，可能会对某些读者产生不适，我会尽可能的用白话把其中原理讲解的通俗易懂。

## PCA简介

PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。通俗讲就是将高纬度数据变为低维度，例如基于电商的用户数据可能有上亿维，我们可以采用PCA把维度从亿级别降低到万级别。

## 向量的内积

两个维数相同的向量的内积被定义为：

$$(a_1,a_2,...,a_n)·(b_1,b_2,...b_n)^T = a_1b_1+a_2b_2+...+a_nb_n$$

这个定义很好理解，我们在高中就已经学过，那么内积的几何意义是什么呢，我们看个图


