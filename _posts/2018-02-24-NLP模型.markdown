---
layout: post
title: 'NLP模型'
subtitle: 'NLP模型浅析'
date: 2018-02-24
categories: 神经网络
cover: ''
tags: 神经网络
---


## 前言
DP算法在图像识别领域取得了惊人的效果，近些年，也不断有人挖掘除了语言这种高层次抽象中的本质，从而让DP在NLP领域不断取得新的突破，其中最关键的核心技术就是Word2Vec，也称Word Embeddings，中文有很多叫法，比较普遍的是”词向量”或“词嵌入”。本文也将会从这个点开始讲起。

## 词向量
要把自然语言处理问题转换为机器可以理解的内容，第一步就是要想办法把自然语言转换为数字，到目前为止，最直观的表示方法One-hot
就是建立一个词汇表，例如一个用来表示10000个词汇的词汇表，里面包含了10000个长度为10000的向量，每一个向量中绝大多数元素都是0，只有一个维度的值为1，这个维度就代表了这个词，我们看个例子：

苹果(5304) 苹果这个词向量是在第5304的位置为1其他位置为0，我们用$O_{5304}$表示苹果
$$\begin{bmatrix}{0}\\{0}\\{·}\\{·}\\{1}\\{·}\\{·}\\{0}\end{bmatrix}$$

西瓜(9230) 西瓜这个词向量是在第9230的位置为1其他位置为0，我们用$O_{9230}$表示西瓜
$$\begin{bmatrix}{0}\\{0}\\{0}\\{·}\\{·}\\{1}\\{·}\\{0}\end{bmatrix}$$

用这种方式来表示词汇会非常简洁，每个单词分配一个对应的ID即可，但是也有其缺点，这种方法会让每个词汇孤立起来，例如苹果和西瓜，本质上都是水果，但是机器没法找出其中的关系。为了解决这个问题，我们引入了一种特征化的表示方法，看个例子。

我们针对四个词，给他们做了特征标注

|  | 男人 | 女人 | 苹果 | 西瓜 |
| --- | --- | --- | --- | --- |
| 性别 | 1 | -1 | 0 | 0.001 |
| 水果 | 0.001 | 0.0002 | 0.98 | 0.99 |
| 食物 | 0.002 | 0 | 1 | 0.97 |
| ... | ... |... |... |... |

假设我们对每个词汇进行了200次的特征标注，那么每个词汇的的词向量长度就是200，例如这里的苹果我们用$e_{5304}$表示值为
$$\begin{bmatrix}{0}\\{0.98}\\{1}\\{·}\\{·}\\{.}\\{·}\end{bmatrix}$$

西瓜用$e_{9230}$表示值为
$$\begin{bmatrix}{0.001}\\{0.99}\\{0.97}\\{·}\\{·}\\{.}\\{·}\end{bmatrix}$$

如果我们有一个猜测后续词汇的场景，训练数据是“我想喝苹果汁”，需要猜测的是“我想喝_汁”，如果使用带有特征值的词向量，机器泛华效果会更好，很容易就能猜测出西瓜这个词。


